{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis with [Python](https://www.python.org/) &nbsp;<a href=\"https://www.python.org/\"><img src=\"https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png\" style=\"max-width: 35px; display: inline\" alt=\"Python\"/></a>\n",
    "\n",
    "_Visualization and denoising of handwritten digits_\n",
    "\n",
    "--- \n",
    "\n",
    "\n",
    "In this tutorial, we illustrate some of the uses of Principal Component Analysis (PCA) in data analysis. Indeed, while PCA is fundamentally a dimensionality reduction algorithm, it can also be useful as a tool for visualization, noise filtering, feature extraction and much more. \n",
    "\n",
    "Here, we will take a look at the [digit dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py) included with [`Scikit-Learn`](https://scikit-learn.org)\n",
    "\n",
    "---\n",
    "\n",
    "_Based on [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Digits\n",
    "\n",
    "The digits dataset is made of $n$ small images in black and white. Each image represents a handwritten number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Question:** How many images does this dataset contain? Which size are the images?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** visualize the first few data points.</span>\n",
    "\n",
    "- Choose a suitable colormap,\n",
    "- You can use the [`imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/plot_digits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## PCA as Dimensionality Reduction\n",
    "\n",
    "So we are looking at points of dimension 64, which can be complicated to visualize. To gain some intuition into the relationships between these points, we can use PCA to project them into a more manageable number of dimensions, say two (or three)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Perform PCA on the digit data.</span>\n",
    "\n",
    "- Project from 64 to 2 dimensions.\n",
    "- What is the variance explained by each of the component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pca_digits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Plot the first two principal components of each point, colored according to its value.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scatter_digits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ Here, the points are colored according to their numerical value. However, the PCA decomposition obtained was performed in an unsupervised manner, i.e. without using the associated labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Question:** How well can images be reconstructed when projected into a $d$-dimensional space?</span>\n",
    "\n",
    "- Visually compare the initial digits with those obtained after: (i) projection onto the PCA space (`fit_transform`) followed by (ii) inverse transformation (`inverse_transform`). \n",
    "- Evaluate the effect of the dimension $d$ of the PCA space.\n",
    "- Measure the mean squared error ([MSE](https://en.wikipedia.org/wiki/Mean_squared_error)) between initial and reconstructed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "d = ...\n",
    "pca = PCA(d)  # project from 64 to 2 dimensions\n",
    "projected = ...\n",
    "reconstructed = ...\n",
    "\n",
    "print('MSE:', ...)\n",
    "print('')\n",
    "\n",
    "# --- #\n",
    "# Initial images\n",
    "\n",
    "print('> Initial images')\n",
    "\n",
    "[...]\n",
    "\n",
    "# --- #\n",
    "# Reconstructed Images \n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/reconstructed_digits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Plot the evolution of the MSE as a function of $d$.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MSE_digits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we note that above a certain number of components, MSE no longer decreases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Using a suitable tool, determine the \"right\" number of components to keep.</span>\n",
    "\n",
    "An essential element in the practical use of PCA is the ability to estimate the number of components needed to describe the data. This can be determined by examining <span style=\"color:purple\">**...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO BE COMPLETED ##\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/nb_components.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An essential element in the practical use of PCA is the ability to estimate the number of components needed to describe the data. This can be determined by examining the cumulative _ratio of explained variance_ as a function of the number of components.\n",
    "\n",
    "> For example, the first 10 components contain around 75% of the variance, whereas it takes around 50 components to describe almost 100% of the variance. In particular, our previous two-dimensional projection loses a lot of information, and we would need around 20 components to retain 90% of the variance.  \n",
    "\n",
    "\n",
    "This curve quantifies how much of the total 64-dimensional variance is contained in the first $d$ components.\n",
    "Examining this graph for a high-dimensional dataset can help you understand the level of redundancy present in its features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components in a picture?\n",
    "\n",
    "In the context of images, performing a PCA consists in determining the most appropriate groupings of pixels which, once added together (with an appropriate weighting), enable the reconstruction of the original image.\n",
    "\n",
    "The `plot_pca` function below, taken from the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/06.00-figure-code.html#Digits-PCA-Components) allows to visualize this decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_pca import plot_pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = 9\n",
    "pca = PCA(n_components=d)\n",
    "projected = pca.fit_transform(digits.data)\n",
    "\n",
    "# --- #\n",
    "\n",
    "for i in range(10):\n",
    "    id = np.where(digits.target == i)[0][-1]\n",
    "    fig = plot_pca_components(digits.data[id], projected[id], pca.mean_, pca.components_, n_components=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PCA as Noise Filtering\n",
    "\n",
    "PCA can also be used as a filtering approach for noisy data.\n",
    "\n",
    "The **idea** is that all components whose variance is much greater than the effect of noise should be relatively unaffected by noise.\n",
    "So, if you reconstruct the data using only the largest subset of principal components, you should preferentially retain the signal and reject the noise.\n",
    "\n",
    "Let's see what happens with the digits data.\n",
    "\n",
    "The function below makes it easy to check the first 4 digits of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap = 'binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "        \n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Add some random noise to create a noisy dataset, and replot it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "rng = np.random.default_rng(12)\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/data_noisy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> The visualization makes the presence of this random noise clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:purple\"> **Question:** How many components should be kept in the PCA decomposition to ensure that the projection retains at least 50% of the total variance?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pca_noisy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here 50% of the variance amounts to 12 principal components, out of the 64 original features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\"> **Todo:** Reconstruct the filtered digits.</span>\n",
    "\n",
    "- Project on the ACP space,\n",
    "- Use the inverse transformation to determine the denoised digits,\n",
    "- Compare with the noiseless digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/filtered_noisy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- This signal preserving/noise filtering property makes PCA a very useful feature selection routineâ€”for example, rather than training a classifier on very high-dimensional data, you might instead train the classifier on the lower-dimensional principal component representation, which will automatically serve to filter out random noise in the inputs. -->"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "513788764cd0ec0f97313d5418a13e1ea666d16d72f976a8acadce25a5af2ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
